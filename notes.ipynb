{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a distance runner I love to go onto the TFFRS reporting system to look up information about races, my personal best times or how other teams performed.\n",
    "\n",
    "There was a time when I was trying to score a meet for track and field just by looking at the website and thought, \"man I wish I could just have an api to get me all that information\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is kinda annoying(from tffrs terms and condition)\n",
    "\n",
    "    Other than as expressly allowed herein, you may not download, post, display, publish, copy, reproduce, distribute, transmit, modify, perform, broadcast, transfer, create derivative works from, sell or otherwise exploit any content, code, data or materials on or available through the TFRRS web site.\n",
    "\n",
    "So I'm just going to see if I can create a basic api with some simple end points, not for profit\n",
    "Thinking of just going by webscraping with beautiful soup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections.abc import MutableMapping\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tfrrs.org/teams/PA_college_m_Moravian.html\n",
    "\n",
    "looking at the above link for getting a team page:\n",
    "\n",
    "    https://www.tfrrs.org/teams/STATE_college_(m/f)_Team_Name.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.tfrrs.org/teams/PA_college_m_Moravian.html\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup\n",
    "# would show a ton of html elements but because at the time of writing this there is no full roster I will use an older link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.tfrrs.org/teams/tf/PA_college_m_Moravian.html?config_hnd=224\" #do not know what config_hnd=224 means\n",
    "page = requests.get(URL)\n",
    "\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "roster_table = soup.find_all(\"table\", class_=\"tablesaw\")[0] #indexing it because it returns a list\n",
    "# gets the roster table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "athlete_rows = roster_table.find_all(\"tr\")\n",
    "# want to get athlete names and years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clemson, Brad'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = athlete_rows[1].find('a')\n",
    "year = athlete_rows[1].find_all('td')[0].text.strip()\n",
    "year.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clemson, Brad SR-4\n",
      "DeRafelo, Dominic SR-4\n",
      "Duffy, Liam JR-3\n",
      "Farrell, Jake FR-1\n",
      "Fitting, Liam SO-2\n",
      "Ford, Jordan SO-2\n",
      "Frank, Casey SO-2\n",
      "Gingrich, Peter SR-4\n",
      "Glennon, Richard SR-4\n",
      "Hajel, Nathan FR-1\n",
      "Houghton, Shane SR-4\n",
      "Jancsarics, Christian JR-3\n",
      "Kleinberg, Geoffrey FR-1\n",
      "Lerch, Michael SR-4\n",
      "Mangini, Josh SO-2\n",
      "Nahf, Owen FR-1\n",
      "Petre, Paul SO-2\n",
      "Poniktera, Wyatt FR-1\n",
      "Riley, John FR-1\n",
      "Ward, Brendon SO-2\n"
     ]
    }
   ],
   "source": [
    "athlete_rows.pop(0)\n",
    "for athlete_info in athlete_rows:\n",
    "    name = athlete_info.find_all('td')[0].text.strip()\n",
    "    year = athlete_info.find_all('td')[1].text.strip()\n",
    "    print(name, year)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top could maybe be refactored into list comprehensions or to a dictionary comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    page = requests.get(url)\n",
    "    return BeautifulSoup(page.content, \"html.parser\")\n",
    "    \n",
    "def get_athletes(url):\n",
    "    html = get_soup(url)\n",
    "    roster_table = html.find_all(\"table\", class_=\"tablesaw\")[0]\n",
    "    athlete_rows = roster_table.find_all(\"tr\")\n",
    "    athlete_rows.pop(0)\n",
    "    athletes = []\n",
    "    for athlete_info in athlete_rows:\n",
    "        name = athlete_info.find_all('td')[0].text.strip()\n",
    "        year = athlete_info.find_all('td')[1].text.strip()\n",
    "        athletes.append({'name':name, 'year':year})\n",
    "    return athletes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Aviles, Elias', 'year': 'JR-3'},\n",
       " {'name': 'Clemson, Brad', 'year': 'SR-4'},\n",
       " {'name': 'DeRafelo, Dominic', 'year': 'SR-4'},\n",
       " {'name': 'Duffy, Liam', 'year': 'JR-3'},\n",
       " {'name': 'Farrell, Jake', 'year': 'FR-1'},\n",
       " {'name': 'Fitting, Liam', 'year': 'SO-2'},\n",
       " {'name': 'Ford, Jordan', 'year': 'SO-2'},\n",
       " {'name': 'Frank, Casey', 'year': 'SO-2'},\n",
       " {'name': 'Gingrich, Peter', 'year': 'SR-4'},\n",
       " {'name': 'Glennon, Richard', 'year': 'SR-4'},\n",
       " {'name': 'Hajel, Nathan', 'year': 'FR-1'},\n",
       " {'name': 'Houghton, Shane', 'year': 'SR-4'},\n",
       " {'name': 'Jancsarics, Christian', 'year': 'JR-3'},\n",
       " {'name': 'Kleinberg, Geoffrey', 'year': 'FR-1'},\n",
       " {'name': 'Lerch, Michael', 'year': 'SR-4'},\n",
       " {'name': 'Mangini, Josh', 'year': 'SO-2'},\n",
       " {'name': 'Nahf, Owen', 'year': 'FR-1'},\n",
       " {'name': 'Petre, Paul', 'year': 'SO-2'},\n",
       " {'name': 'Poniktera, Wyatt', 'year': 'FR-1'},\n",
       " {'name': 'Riley, John', 'year': 'FR-1'},\n",
       " {'name': 'Ward, Brendon', 'year': 'SO-2'}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_athletes(\"https://www.tfrrs.org/teams/PA_college_m_Moravian.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try this with a different team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Affolder, Luke', 'year': 'FR-1'},\n",
       " {'name': 'Barclay, Sebastian', 'year': 'FR-1'},\n",
       " {'name': 'Bienenfeld, Aaron', 'year': 'SR-4'},\n",
       " {'name': 'Brown, Caleb', 'year': 'FR-1'},\n",
       " {'name': 'Brown, Reed', 'year': 'SR-4'},\n",
       " {'name': 'Cook, Elliott', 'year': 'FR-1'},\n",
       " {'name': 'Erickson, Matthew', 'year': 'FR-1'},\n",
       " {'name': 'Fitzgerald, Ignatius', 'year': 'FR-1'},\n",
       " {'name': 'Folmli, Angus', 'year': 'JR-3'},\n",
       " {'name': 'Gormley, James', 'year': 'JR-3'},\n",
       " {'name': 'Hocker, Cole', 'year': 'SO-2'},\n",
       " {'name': 'Holland, EJ', 'year': 'FR-1'},\n",
       " {'name': 'Hunter, Charlie', 'year': 'JR-3'},\n",
       " {'name': 'Hussein, Abdinasir', 'year': 'FR-1'},\n",
       " {'name': 'Laverty, Sean', 'year': 'SR-4'},\n",
       " {'name': 'Mestler, Jackson', 'year': 'SR-4'},\n",
       " {'name': 'Mestler, Vincent', 'year': 'FR-1'},\n",
       " {'name': 'Neumaier, Steve', 'year': 'SR-4'},\n",
       " {'name': 'Norman, Quincy', 'year': 'SO-2'},\n",
       " {'name': 'Peralta, Luis', 'year': 'SO-2'},\n",
       " {'name': 'Perez, Diego', 'year': 'FR-1'},\n",
       " {'name': 'Reynolds, Benjamin', 'year': 'FR-1'},\n",
       " {'name': 'Simone, Christian', 'year': 'FR-1'},\n",
       " {'name': 'Stein, Cameron', 'year': 'FR-1'},\n",
       " {'name': 'Teare, Cooper', 'year': 'SR-4'},\n",
       " {'name': 'Wisner, Matt', 'year': 'SR-4'},\n",
       " {'name': 'Yearian, Jack', 'year': 'SR-4'}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_athletes('https://www.tfrrs.org/teams/tf/OR_college_m_Oregon.html?config_hnd=222')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastic, I have my first flask endpoint.\n",
    "Kinda I still have to know how to get the year incorporated but I might have a solution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.tfrrs.org/teams/PA_college_m_Moravian.html\"\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "form_control = soup.find(\"select\", class_=\"form-control\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<select class=\"form-control\" name=\"config_hnd\" onchange=\"seasonSelect(this, 'window', false);\">\n",
       "<option selected=\"\" value=\"266\">\n",
       "2022 Cross Country\n",
       "              </option>\n",
       "<option value=\"255\">\n",
       "2022 Outdoor\n",
       "              </option>\n",
       "<option value=\"240\">\n",
       "2021-22 Indoor\n",
       "              </option>\n",
       "<option value=\"224\">\n",
       "2021 Cross Country\n",
       "              </option>\n",
       "<option value=\"216\">\n",
       "2021 Outdoor\n",
       "              </option>\n",
       "<option value=\"205\">\n",
       "2020-21 Indoor\n",
       "              </option>\n",
       "<option value=\"197\">\n",
       "2020 Cross Country\n",
       "              </option>\n",
       "<option value=\"189\">\n",
       "2020 Outdoor\n",
       "              </option>\n",
       "<option value=\"178\">\n",
       "2019-20 NCAA Indoor\n",
       "              </option>\n",
       "<option value=\"169\">\n",
       "2019 Cross Country\n",
       "              </option>\n",
       "<option value=\"160\">\n",
       "2019 Outdoor\n",
       "              </option>\n",
       "<option value=\"148\">\n",
       "2018-19 NCAA Indoor\n",
       "              </option>\n",
       "<option value=\"140\">\n",
       "2018 Cross Country\n",
       "              </option>\n",
       "<option value=\"131\">\n",
       "2018 Outdoor\n",
       "              </option>\n",
       "<option value=\"125\">\n",
       "2017-2018 NCAA Indoor\n",
       "              </option>\n",
       "<option value=\"117\">\n",
       "2017 Cross Country\n",
       "              </option>\n",
       "<option value=\"110\">\n",
       "2017 NCAA Outdoor\n",
       "              </option>\n",
       "<option value=\"104\">\n",
       "2016-2017 NCAA Indoor\n",
       "              </option>\n",
       "<option value=\"98\">\n",
       "2016 Cross Country\n",
       "              </option>\n",
       "<option value=\"93\">\n",
       "2016 NCAA Outdoor\n",
       "              </option>\n",
       "<option value=\"85\">\n",
       "2015-2016 NCAA Indoor\n",
       "              </option>\n",
       "<option value=\"80\">\n",
       "2015 Cross Country\n",
       "              </option>\n",
       "<option value=\"74\">\n",
       "2015 Outdoor\n",
       "              </option>\n",
       "<option value=\"67\">\n",
       "2014-2015 Indoor\n",
       "              </option>\n",
       "<option value=\"63\">\n",
       "2014 Cross Country\n",
       "              </option>\n",
       "<option value=\"56\">\n",
       "2014 Outdoor\n",
       "              </option>\n",
       "<option value=\"49\">\n",
       "2013-2014 Indoor\n",
       "              </option>\n",
       "<option value=\"45\">\n",
       "2013 Cross Country\n",
       "              </option>\n",
       "<option value=\"42\">\n",
       "2013 Outdoor\n",
       "              </option>\n",
       "<option value=\"31\">\n",
       "2012-2013 Indoor\n",
       "              </option>\n",
       "<option value=\"27\">\n",
       "2012 Cross Country\n",
       "              </option>\n",
       "<option value=\"23\">\n",
       "2012 Outdoor\n",
       "              </option>\n",
       "<option value=\"19\">\n",
       "2011-12 Indoor\n",
       "              </option>\n",
       "<option value=\"15\">\n",
       "2011 Outdoor\n",
       "              </option>\n",
       "<option value=\"11\">\n",
       "2010-11 Indoor\n",
       "              </option>\n",
       "<option value=\"7\">\n",
       "2010 Outdoor\n",
       "              </option>\n",
       "<option value=\"3\">\n",
       "2009-10 Indoor\n",
       "              </option>\n",
       "</select>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "form_control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bingo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_info = form_control.find_all(\"option\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'': '2022 Cross Country'},\n",
       " {'255': '2022 Outdoor'},\n",
       " {'240': '2021-22 Indoor'},\n",
       " {'224': '2021 Cross Country'},\n",
       " {'216': '2021 Outdoor'},\n",
       " {'205': '2020-21 Indoor'},\n",
       " {'197': '2020 Cross Country'},\n",
       " {'189': '2020 Outdoor'},\n",
       " {'178': '2019-20 NCAA Indoor'},\n",
       " {'169': '2019 Cross Country'},\n",
       " {'160': '2019 Outdoor'},\n",
       " {'148': '2018-19 NCAA Indoor'},\n",
       " {'140': '2018 Cross Country'},\n",
       " {'131': '2018 Outdoor'},\n",
       " {'125': '2017-2018 NCAA Indoor'},\n",
       " {'117': '2017 Cross Country'},\n",
       " {'110': '2017 NCAA Outdoor'},\n",
       " {'104': '2016-2017 NCAA Indoor'},\n",
       " {'98': '2016 Cross Country'},\n",
       " {'93': '2016 NCAA Outdoor'},\n",
       " {'85': '2015-2016 NCAA Indoor'},\n",
       " {'80': '2015 Cross Country'},\n",
       " {'74': '2015 Outdoor'},\n",
       " {'67': '2014-2015 Indoor'},\n",
       " {'63': '2014 Cross Country'},\n",
       " {'56': '2014 Outdoor'},\n",
       " {'49': '2013-2014 Indoor'},\n",
       " {'45': '2013 Cross Country'},\n",
       " {'42': '2013 Outdoor'},\n",
       " {'31': '2012-2013 Indoor'},\n",
       " {'27': '2012 Cross Country'},\n",
       " {'23': '2012 Outdoor'},\n",
       " {'19': '2011-12 Indoor'},\n",
       " {'15': '2011 Outdoor'},\n",
       " {'11': '2010-11 Indoor'},\n",
       " {'7': '2010 Outdoor'},\n",
       " {'3': '2009-10 Indoor'}]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_hnd = [{str(year).split('\"')[1]: year.text.strip()} for year in year_info] #the key is the code and the descrption is the value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make this a function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year_keys(soup):\n",
    "    form_control = soup.find(\"select\", class_=\"form-control\")\n",
    "    return [{str(year).split('\"')[1]: year.text.strip()} for year in year_info] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made \"Hermes\", the messenger god, the api. Super clever. Right now working on making sure the class works. First end point is I want to be able to return a roster for team_name xc/tf m/w year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class Hermes:\n",
    "    def __init__(self):\n",
    "        self.URL = \"https://www.tfrrs.org/\"\n",
    "\n",
    "    def get_soup(self, url):\n",
    "        page = requests.get(url)\n",
    "        return BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    def get_year_keys(self, state, team_name, gender): #for getting the key \"configure_hnd\" so we can get the html page from a certain year\n",
    "        soup = self.get_soup(self.URL + f'teams/{state.upper()}_college_{gender.lower()}_{team_name}.html')\n",
    "        form_control = soup.find(\"select\", class_=\"form-control\")\n",
    "        year_info = form_control.find_all(\"option\")\n",
    "        year_info.pop(0) # dictionary comprehension to get the keys and values for the years\n",
    "        return {year.text.strip().replace('NCAA','').replace(' ','_').replace('__','_') : str(year).split('\"')[1] for year in year_info}\n",
    "\n",
    "\n",
    "    def get_roster(self, state, team_name, gender, season):\n",
    "        roster_url = self.URL + f'teams/{state.upper()}_college_{gender.lower()}_{team_name}.html'\n",
    "        year_keys = self.get_year_keys(state, team_name, gender)\n",
    "        roster_url += f'?config_hnd={year_keys[season]}'\n",
    "        html = self.get_soup(roster_url)\n",
    "        roster_table = html.find_all(\"table\", class_=\"tablesaw\")[0]\n",
    "        athlete_rows = roster_table.find_all(\"tr\")\n",
    "        athlete_rows.pop(0)\n",
    "        roster = []\n",
    "        for athlete_info in athlete_rows:\n",
    "            name = athlete_info.find_all('td')[0].text.strip()\n",
    "            year = athlete_info.find_all('td')[1].text.strip()\n",
    "            roster.append({'name':name, 'year':year})\n",
    "        return roster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = Hermes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2022_Outdoor': '254',\n",
       " '2021-22_Indoor': '238',\n",
       " '2021_Cross_Country': '222',\n",
       " '2021_Outdoor': '214',\n",
       " '2020-21_Indoor': '203',\n",
       " '2020_Cross_Country': '195',\n",
       " '2020_Outdoor': '187',\n",
       " '2019-20_Indoor': '176',\n",
       " '2019_Cross_Country': '167',\n",
       " '2019_Outdoor': '158',\n",
       " '2018-19_Indoor': '146',\n",
       " '2018_Cross_Country': '138',\n",
       " '2018_Outdoor': '129',\n",
       " '2017-2018_Indoor': '123',\n",
       " '2017_Cross_Country': '115',\n",
       " '2017_Outdoor': '108',\n",
       " '2016-2017_Indoor': '102',\n",
       " '2016_Cross_Country': '96',\n",
       " '2016_Outdoor': '91',\n",
       " '2015-2016_Indoor': '83',\n",
       " '2015_Cross_Country': '78',\n",
       " '2015_Outdoor': '72',\n",
       " '2014-2015_Indoor': '65',\n",
       " '2014_Cross_Country': '60',\n",
       " '2014_Outdoor': '54',\n",
       " '2013-2014_Indoor': '47',\n",
       " '2013_Cross_Country': '43',\n",
       " '2013_Outdoor': '35',\n",
       " '2012-2013_Indoor': '29',\n",
       " '2012_Cross_Country': '25',\n",
       " '2012_Outdoor': '21',\n",
       " '2011-12_Indoor': '17',\n",
       " '2011_Outdoor': '13',\n",
       " '2010-11_Indoor': '9',\n",
       " '2010_Outdoor': '5',\n",
       " '2009-10_Indoor': '1'}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.get_year_keys(state='OR', team_name='Oregon', gender='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Aviles, Elias', 'year': 'JR-3'},\n",
       " {'name': 'Clemson, Brad', 'year': 'SR-4'},\n",
       " {'name': 'DeRafelo, Dominic', 'year': 'SR-4'},\n",
       " {'name': 'Duffy, Liam', 'year': 'JR-3'},\n",
       " {'name': 'Farrell, Jake', 'year': 'FR-1'},\n",
       " {'name': 'Fitting, Liam', 'year': 'SO-2'},\n",
       " {'name': 'Ford, Jordan', 'year': 'SO-2'},\n",
       " {'name': 'Frank, Casey', 'year': 'SO-2'},\n",
       " {'name': 'Gingrich, Peter', 'year': 'SR-4'},\n",
       " {'name': 'Glennon, Richard', 'year': 'SR-4'},\n",
       " {'name': 'Hajel, Nathan', 'year': 'FR-1'},\n",
       " {'name': 'Houghton, Shane', 'year': 'SR-4'},\n",
       " {'name': 'Jancsarics, Christian', 'year': 'JR-3'},\n",
       " {'name': 'Kleinberg, Geoffrey', 'year': 'FR-1'},\n",
       " {'name': 'Lerch, Michael', 'year': 'SR-4'},\n",
       " {'name': 'Mangini, Josh', 'year': 'SO-2'},\n",
       " {'name': 'Nahf, Owen', 'year': 'FR-1'},\n",
       " {'name': 'Petre, Paul', 'year': 'SO-2'},\n",
       " {'name': 'Poniktera, Wyatt', 'year': 'FR-1'},\n",
       " {'name': 'Riley, John', 'year': 'FR-1'},\n",
       " {'name': 'Ward, Brendon', 'year': 'SO-2'}]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.get_roster('PA', 'Moravian', 'm', '2021_Cross_Country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a good start to our first endpoint\n",
    "other endpoints should be:\n",
    "    \n",
    "    get an athletes pr's\n",
    "    get an athletes races\n",
    "    get a conference's teams\n",
    "    get a teams's profile(conference, region(s), division, location)\n",
    "    get performance lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "400\n",
      "800\n",
      "1500\n",
      "5000\n",
      "10,000\n",
      "110H\n",
      "400H\n",
      "3000S\n",
      "4x100\n",
      "4x400\n",
      "4x800\n",
      "PV\n",
      "LJ\n",
      "SP\n",
      "DT\n",
      "HT\n",
      "JT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "page = requests.get('https://www.tfrrs.org/teams/tf/PA_college_m_Moravian.html')\n",
    "html = BeautifulSoup(page.content, \"html.parser\")\n",
    "roster_table = html.find_all(\"table\", class_=\"tablesaw\")[0]\n",
    "athlete_rows = roster_table.find_all(\"tr\")\n",
    "athlete_rows.pop(0)\n",
    "# athlete_rows\n",
    "# roster = []\n",
    "name = 'Gray_Trevor'\n",
    "for athlete_info in athlete_rows:\n",
    "    found = athlete_info.find_all('td')[0].text.strip().replace(', ','_')\n",
    "    print(found)\n",
    "    if name == found:\n",
    "        print(f'hello {name}')\n",
    "        print(athlete_info.find_all('a')[0]['href'])\n",
    "#     name = athlete_info.find_all('td')[0].text.strip()\n",
    "#     year = athlete_info.find_all('td')[1].text.strip()\n",
    "#     roster.append({'name':name, 'year':year})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gotta refactor the way we get the roster table. We got the top marks for a season of track instead of the roster table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class Hermes:\n",
    "    def __init__(self):\n",
    "        self.URL = \"https://www.tfrrs.org/\"\n",
    "\n",
    "    def get_soup(self, url):\n",
    "        page = requests.get(url)\n",
    "        return BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    def get_year_keys(self, state, team_name, gender): #for getting the key \"configure_hnd\" so we can get the html page from a certain year\n",
    "        soup = self.get_soup(self.URL + f'teams/{state.upper()}_college_{gender.lower()}_{team_name}.html')\n",
    "        form_control = soup.find(\"select\", class_=\"form-control\")\n",
    "        year_info = form_control.find_all(\"option\")\n",
    "        year_info.pop(0) # dictionary comprehension to get the keys and values for the years\n",
    "        return {year.text.strip().replace('NCAA','').replace(' ','_').replace('__','_') : str(year).split('\"')[1] for year in year_info}\n",
    "\n",
    "\n",
    "    def get_roster(self, state, team_name, gender, season):\n",
    "        page_url = self.URL + f'teams/{state.upper()}_college_{gender.lower()}_{team_name}.html'\n",
    "        year_keys = self.get_year_keys(state, team_name, gender)\n",
    "        page_url += f'?config_hnd={year_keys[season]}'\n",
    "        html = self.get_soup(page_url)\n",
    "        roster_rows = self.get_roster_table(page_url)\n",
    "        roster = []\n",
    "        for athlete_info in athlete_rows:\n",
    "            name = athlete_info.find_all('td')[0].text.strip()\n",
    "            year = athlete_info.find_all('td')[1].text.strip()\n",
    "            roster.append({'name':name, 'year':year})\n",
    "        return roster\n",
    "\n",
    "        \n",
    "\n",
    "    def get_roster_table(self, page_url):\n",
    "        html = self.get_soup(page_url)\n",
    "        html_tables = html.find_all(\"table\", class_=\"tablesaw\")\n",
    "        for table in html_tables:\n",
    "            if table.find('th').text.strip() == 'NAME':\n",
    "                roster_table = table\n",
    "        roster_rows = roster_table.find_all(\"tr\")\n",
    "        roster_rows.pop(0)\n",
    "        return roster_rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVENT\n",
      "                \n",
      "NAME\n",
      "                \n",
      "DATE\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "page = requests.get('https://www.tfrrs.org/teams/tf/PA_college_m_Moravian.html')\n",
    "html = BeautifulSoup(page.content, \"html.parser\")\n",
    "tables= html.find_all(\"table\", class_=\"tablesaw\") # was roster table\n",
    "for table in tables:\n",
    "    print(table.find('th').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello Gray_Trevor\n"
     ]
    }
   ],
   "source": [
    "page = requests.get('https://www.tfrrs.org/teams/tf/PA_college_m_Moravian.html')\n",
    "html = BeautifulSoup(page.content, \"html.parser\")\n",
    "html_tables = html.find_all(\"table\", class_=\"tablesaw\")\n",
    "\n",
    "for table in html_tables:\n",
    "    if table.find('th').text.strip() == 'NAME':\n",
    "        roster_table = table\n",
    "athlete_rows = roster_table.find_all(\"tr\")\n",
    "athlete_rows.pop(0)\n",
    "roster = []\n",
    "\n",
    "name = 'Gray_Trevor'\n",
    "for athlete_info in athlete_rows:\n",
    "    if name == athlete_info.find_all('td')[0].text.strip().replace(', ','_'):\n",
    "        print(f'hello {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello Gray_Trevor\n",
      "/athletes/7983217/Moravian/Trevor_Gray.html\n"
     ]
    }
   ],
   "source": [
    "def get_roster_table(): # would be self and url for class method\n",
    "    page = requests.get('https://www.tfrrs.org/teams/tf/PA_college_m_Moravian.html')\n",
    "    html = BeautifulSoup(page.content, \"html.parser\")\n",
    "    html_tables = html.find_all(\"table\", class_=\"tablesaw\")\n",
    "    for table in html_tables:\n",
    "        if table.find('th').text.strip() == 'NAME':\n",
    "            roster_table = table\n",
    "    roster_rows = roster_table.find_all(\"tr\")\n",
    "    roster_rows.pop(0)\n",
    "    return roster_rows\n",
    "rows = get_roster_table()\n",
    "\n",
    "name = 'Gray_Trevor'\n",
    "for athlete_info in rows:\n",
    "    if name == athlete_info.find_all('td')[0].text.strip().replace(', ','_'):\n",
    "        print(f'hello {name}')\n",
    "        print(athlete_info.find_all('a')[0]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class Hermes:\n",
    "    def __init__(self):\n",
    "        self.URL = \"https://www.tfrrs.org/\"\n",
    "    \n",
    "\n",
    "    def get_roster(self, state, team_name, gender, season):\n",
    "        team_html = self.get_team_html(state, team_name, gender, season)\n",
    "        roster_rows = self.get_roster_table(team_html)\n",
    "        roster = []\n",
    "        for athlete_info in roster_rows:\n",
    "            name = athlete_info.find_all('td')[0].text.strip()\n",
    "            year = athlete_info.find_all('td')[1].text.strip()\n",
    "            roster.append({'name':name, 'year':year})\n",
    "        return roster\n",
    "    \n",
    "    def get_athlete_bests(self, name, state, team_name, gender, season):\n",
    "        athlete_html = self.get_athlete_html(name, state, team_name, gender, season)\n",
    "        table_bests = athlete_html.find(\"table\", class_=\"table bests\")\n",
    "        table_rows = table_bests.find_all(\"td\")\n",
    "        bests = {}\n",
    "        for i in range(0,len(rows), 2):\n",
    "            bests[self.remove_spaces(rows[i].text)] = self.remove_spaces(rows[i+1].text)\n",
    "        print(bests)\n",
    "\n",
    "\n",
    "    def get_athlete_html(self, name, state, team_name, gender, season):\n",
    "        team_html = self.get_team_html(state, team_name, gender, season)\n",
    "        roster_rows = self.get_roster_table(team_html)\n",
    "        for athlete_info in roster_rows: # does a look up of the athlete by name\n",
    "            if name == athlete_info.find_all('td')[0].text.strip().replace(', ','_'):\n",
    "                athlete_url = self.URL + athlete_info.find_all('a')[0]['href']\n",
    "                break\n",
    "        return self.get_soup(athlete_url)\n",
    "\n",
    "    def get_soup(self, url): # gets html with beautiful soup\n",
    "        page = requests.get(url)\n",
    "        return BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    def get_year_keys(self, state, team_name, gender): # for getting the key \"configure_hnd\" so we can get the html page from a certain year\n",
    "        soup = self.get_soup(self.URL + f'teams/{state.upper()}_college_{gender.lower()}_{team_name}.html')\n",
    "        form_control = soup.find(\"select\", class_=\"form-control\")\n",
    "        year_info = form_control.find_all(\"option\")\n",
    "        year_info.pop(0) # dictionary comprehension to get the keys and values for the years\n",
    "        return {year.text.strip().replace('NCAA','').replace(' ','_').replace('__','_') : str(year).split('\"')[1] for year in year_info}\n",
    "        \n",
    "    def get_team_html(self, state, team_name, gender, season):\n",
    "        year_keys = self.get_year_keys(state, team_name, gender)\n",
    "        page_url = self.URL + f'teams/{state.upper()}_college_{gender.lower()}_{team_name}.html'\n",
    "        page_url += f'?config_hnd={year_keys[season]}'\n",
    "        return self.get_soup(page_url)\n",
    "\n",
    "    def get_roster_table(self, html):\n",
    "        html_tables = html.find_all(\"table\", class_=\"tablesaw\")\n",
    "        for table in html_tables: # there are multiple tables on some pages especially with track teams\n",
    "            if table.find('th').text.strip() == 'NAME': # athlete table has a header with NAME\n",
    "                roster_table = table\n",
    "        roster_rows = roster_table.find_all(\"tr\")\n",
    "        roster_rows.pop(0) # pop the first item in the list because it is just NAME and YEAR\n",
    "        return roster_rows\n",
    "\n",
    "     \n",
    "    def remove_spaces(self, string):\n",
    "        pattern = re.compile(r'\\s+')\n",
    "        return re.sub(pattern, '', string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = Hermes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    " \n",
    "def remove_spaces(string):\n",
    "    pattern = re.compile(r'\\s+')\n",
    "    return re.sub(pattern, '', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'800': '2:06.72', '10,000': '34:35.67', '1500': '4:17.47', '3000S': '10:02.61', 'MILE': '4:42.71', '5K(XC)': '17:56.0', '3000': '9:37.20', '6K(XC)': '20:44.5', '5000': '16:33.66', '8K(XC)': '27:12.1'}\n"
     ]
    }
   ],
   "source": [
    "athlete = h.get_athlete_html('Lerch_Michael', 'PA', 'Moravian', 'm', '2021_Cross_Country')\n",
    "table_bests = athlete.find(\"table\", class_=\"table bests\")\n",
    "table_rows = table_bests.find_all(\"td\")\n",
    "# for row in rows:\n",
    "#     entry = row.text.replace(\"\\n\",\"\").strip(\" \")\n",
    "#     print(remove_spaces(row.text))\n",
    "#     print(f'@{entry}@')\n",
    "bests = {}\n",
    "for i in range(0,len(rows), 2):\n",
    "    bests[remove_spaces(rows[i].text)] = remove_spaces(rows[i+1].text)\n",
    "print(bests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_athlete_bests(athlete_html):\n",
    "    table_bests = athlete_html.find(\"table\", class_=\"table bests\")\n",
    "    table_rows = table_bests.find_all(\"td\")\n",
    "    bests = {}\n",
    "    for i in range(0,len(rows), 2):\n",
    "        bests[remove_spaces(rows[i].text)] = remove_spaces(rows[i+1].text)\n",
    "    print(bests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = Hermes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'800': '2:06.72', '10,000': '34:35.67', '1500': '4:17.47', '3000S': '10:02.61', 'MILE': '4:42.71', '5K(XC)': '17:56.0', '3000': '9:37.20', '6K(XC)': '20:44.5', '5000': '16:33.66', '8K(XC)': '27:12.1'}\n"
     ]
    }
   ],
   "source": [
    "h.get_athlete_bests('Lerch_Michael', 'PA', 'Moravian', 'm', '2021_Cross_Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class Hermes:\n",
    "    def __init__(self):\n",
    "        self.URL = \"https://www.tfrrs.org/\"\n",
    "    \n",
    "\n",
    "    def get_roster(self, state, team_name, gender, season):\n",
    "        team_html = self.get_team_html(state, team_name, gender, season)\n",
    "        roster_rows = self.get_roster_table(team_html)\n",
    "        roster = []\n",
    "        for athlete_info in roster_rows:\n",
    "            name = athlete_info.find_all('td')[0].text.strip()\n",
    "            year = athlete_info.find_all('td')[1].text.strip()\n",
    "            roster.append({'name':name, 'year':year})\n",
    "        return roster\n",
    "    \n",
    "    def get_athlete_bests(self, name, state, team_name, gender, season):\n",
    "        athlete_html = self.get_athlete_html(name, state, team_name, gender, season)\n",
    "        table_bests = athlete_html.find(\"table\", class_=\"table bests\")\n",
    "        rows = table_bests.find_all(\"td\")\n",
    "        bests = {}\n",
    "        for i in range(0,len(rows), 2):\n",
    "            event = self.remove_reg(rows[i].text, 'spaces')\n",
    "            time = self.remove_reg(rows[i+1].text, 'spaces')\n",
    "            if event != \"\" or time != \"\":\n",
    "                bests[event] = time\n",
    "        return bests\n",
    "\n",
    "\n",
    "    def get_athlete_html(self, name, state, team_name, gender, season):\n",
    "        team_html = self.get_team_html(state, team_name, gender, season)\n",
    "        roster_rows = self.get_roster_table(team_html)\n",
    "        for athlete_info in roster_rows: # does a look up of the athlete by name\n",
    "            if name == athlete_info.find_all('td')[0].text.strip().replace(', ','_'):\n",
    "                athlete_url = self.URL + athlete_info.find_all('a')[0]['href']\n",
    "                break\n",
    "        return self.get_soup(athlete_url)\n",
    "\n",
    "    def get_soup(self, url): # gets html with beautiful soup\n",
    "        page = requests.get(url)\n",
    "        return BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    def get_year_keys(self, state, team_name, gender): # for getting the key \"configure_hnd\" so we can get the html page from a certain year\n",
    "        soup = self.get_soup(self.URL + f'teams/{state.upper()}_college_{gender.lower()}_{team_name}.html')\n",
    "        form_control = soup.find(\"select\", class_=\"form-control\")\n",
    "        year_info = form_control.find_all(\"option\")\n",
    "        year_info.pop(0) # dictionary comprehension to get the keys and values for the years\n",
    "        return {year.text.strip().replace('NCAA','').replace(' ','_').replace('__','_') : str(year).split('\"')[1] for year in year_info}\n",
    "        \n",
    "    def get_team_html(self, state, team_name, gender, season):\n",
    "        year_keys = self.get_year_keys(state, team_name, gender)\n",
    "        page_url = self.URL + f'teams/{state.upper()}_college_{gender.lower()}_{team_name}.html'\n",
    "        page_url += f'?config_hnd={year_keys[season]}'\n",
    "        return self.get_soup(page_url)\n",
    "\n",
    "    def get_roster_table(self, html):\n",
    "        html_tables = html.find_all(\"table\", class_=\"tablesaw\")\n",
    "        for table in html_tables: # there are multiple tables on some pages especially with track teams\n",
    "            if table.find('th').text.strip() == 'NAME': # athlete table has a header with NAME\n",
    "                roster_table = table\n",
    "        roster_rows = roster_table.find_all(\"tr\")\n",
    "        roster_rows.pop(0) # pop the first item in the list because it is just NAME and YEAR\n",
    "        return roster_rows\n",
    "\n",
    "     \n",
    "    def remove_reg(self, string, reg):\n",
    "        regs = {'spaces':r'\\s+', 'newlines':r'\\n'}\n",
    "        pattern = re.compile(regs[reg])\n",
    "        return re.sub(pattern, '', string)\n",
    "\n",
    "h = Hermes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_html = h.get_athlete_html('Nahf_Owen', 'PA', 'Moravian', 'm', '2021_Cross_Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AARTFC Outdoor Track & Field Championships': {'date': 'May 18-19, 2022', 'events': [{'event': '5000', 'result': '15:16.38', 'place': '10th', 'final': '(F)'}]}, 'Landmark Conference Outdoor Track & Field Championships 2022': {'date': 'May 7-8, 2022', 'events': [{'event': '1500', 'result': '4:09.08', 'place': '12th', 'final': '(F)'}, {'event': '5000', 'result': '15:30.24', 'place': '6th', 'final': '(F)'}]}, 'Carol and John Covert Classic': {'date': 'Apr 29-30, 2022', 'events': [{'event': '800', 'result': '2:03.99', 'place': '39th', 'final': '(F)'}]}, '2022 Greyhound Invitational ': {'date': 'Apr 15, 2022', 'events': [{'event': '1500', 'result': '4:06.74', 'place': '5th', 'final': '(F)'}, {'event': '10,000', 'result': 'DNF'}]}, 'Lehigh T&F Invite': {'date': 'Apr  9, 2022', 'events': [{'event': '5000', 'result': '15:22.04', 'place': '10th', 'final': '(F)'}, {'event': '4x400', 'result': '3:40.27', 'place': '10th', 'final': '(F)'}]}, 'Muhlenberg Invitational': {'date': 'Apr  2, 2022', 'events': [{'event': '1500', 'result': '4:08.30', 'place': '4th', 'final': '(F)'}]}, '2022 Lafayette Open': {'date': 'Mar 26, 2022', 'events': [{'event': '5000', 'result': '15:40.16', 'place': '3rd', 'final': '(F)'}]}, '2022 Landmark Conference Indoor Track & Field Championships': {'date': 'Feb 26, 2022', 'events': [{'event': 'Mile', 'result': '4:38.10', 'place': '10th', 'final': '(F)'}]}, 'Penn State Tune Up': {'date': 'Feb 18, 2022', 'events': [{'event': 'Mile', 'result': '4:26.85', 'place': '12th', 'final': '(F)'}]}, 'Fastrack National Invite': {'date': 'Feb 11, 2022', 'events': [{'event': '3000', 'result': '8:50.16', 'place': '14th', 'final': '(F)'}]}, 'Plex Shootout at Alvernia Univ': {'date': 'Feb  5, 2022', 'events': [{'event': 'Mile', 'result': '4:28.13', 'place': '6th', 'final': '(F)'}]}, '2022 Moravian University Indoor Meet': {'date': 'Jan 22, 2022', 'events': [{'event': '5000', 'result': '16:03.30', 'place': '3rd', 'final': '(F)'}]}, 'Ithaca College vs. Brockport, Moravian & Oneonta': {'date': 'Jan 14, 2022', 'events': [{'event': '3000', 'result': '9:19.34', 'place': '6th', 'final': '(F)'}]}, 'NCAA Division III Metro Region Cross Country Championships': {'date': 'Nov 13, 2021', 'events': [{'event': '8K', 'result': '27:15.0', 'place': '53rd'}]}, '2021 Landmark Conference Cross Country Championships': {'date': 'Oct 30, 2021', 'events': [{'event': '8K', 'result': '26:48.8', 'place': '8th'}]}, 'Rowan Inter-Regional Border Battle': {'date': 'Oct 16, 2021', 'events': [{'event': '8K', 'result': 'DNF'}]}, 'Lehigh Paul Short Run (college)': {'date': 'Oct  1, 2021', 'events': [{'event': '8K', 'result': 'DNF'}]}, 'NJAIA/Osprey Open': {'date': 'Sep 25, 2021', 'events': [{'event': '8K', 'result': '28:07.9', 'place': '34th'}]}, 'Moravian University Invitational': {'date': 'Sep 17, 2021', 'events': [{'event': '6K', 'result': '19:44.1', 'place': '12th'}]}, 'Lehigh Invitational': {'date': 'Sep  3, 2021', 'events': [{'event': '6K', 'result': '20:07.9', 'place': '69th'}]}}\n"
     ]
    }
   ],
   "source": [
    "from unittest import result\n",
    "\n",
    "\n",
    "meet_results_html = a_html.find(id=\"meet-results\").find_all(\"div\")\n",
    "meet_results  = {}\n",
    "for meet in meet_results_html:\n",
    "    title = meet.find(\"thead\").text.strip().replace('\\xa0\\xa0\\xa0', '')\n",
    "    meet_name, date = title.split('\\n')\n",
    "    table_rows = meet.find_all(\"tr\")\n",
    "    meet_results[meet_name] = {}\n",
    "    meet_results[meet_name]['date'] = date\n",
    "    event_list = []\n",
    "    info_keys = ['event', 'result', 'place', 'final']\n",
    "    for i in range(1,len(table_rows)):\n",
    "        event_info = {}\n",
    "        row_info = table_rows[i].text.replace('\\xa0','').split('\\n')\n",
    "        row_info = [element for element in row_info if (element !='' and element != '\\t')]\n",
    "        for j in range(len(row_info)):\n",
    "            event_info[info_keys[j]] = row_info[j]\n",
    "        event_list.append(event_info)\n",
    "    meet_results[meet_name]['events'] = event_list\n",
    "print(meet_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class Hermes:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        A class used to webscrape TFRRS. It has various methods for retrieving important information\n",
    "        regarding XC/TF teams and athletes.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        URL : str\n",
    "            The url for tffrs which will be added to depending on a specific method being used.\n",
    "        \"\"\"\n",
    "        self.URL = \"https://www.tfrrs.org/\"\n",
    "    \n",
    "\n",
    "    def get_roster(self, state, team_name, gender, season):\n",
    "        \"\"\"\n",
    "        This will scrape through the html and retrieve the roster for a specified team.\n",
    "        Will call the get_team_html method given, the state, team_name, gender, and season.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state : str\n",
    "            state where the school is located. (There can be multiple universities with the same name)\n",
    "        \n",
    "        team_name : str\n",
    "            the name of the school\n",
    "        \n",
    "        gender : str\n",
    "            specifies whether we are trying to retrieve men or women's team\n",
    "\n",
    "        season : str\n",
    "            the season for the roster (*year*_Cross_Country, *year*_Indoor, or *year*_Outdoor)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            List of dictionaries containing athlete information\n",
    "        \"\"\"\n",
    "        team_html = self.get_team_html(state, team_name, gender, season)\n",
    "        roster_rows = self.get_table_by_heading(team_html, 'NAME')\n",
    "        roster = []\n",
    "        for athlete_info in roster_rows:\n",
    "            name = athlete_info.find_all('td')[0].text.strip()\n",
    "            year = athlete_info.find_all('td')[1].text.strip()\n",
    "            roster.append({'name':name, 'year':year})\n",
    "        return roster\n",
    "\n",
    "    def get_top_performances(self, state, team_name, gender, season):\n",
    "        info_keys = ['event', 'athlete(s)', 'year', 'time/mark']\n",
    "        team_html = self.get_team_html(state, team_name, gender, season)\n",
    "        rows = self.get_table_by_heading(team_html, 'EVENT') #getting top performance table by the EVENT heading, hackish ik.\n",
    "        performances = []\n",
    "        for row in rows:\n",
    "            perf = {}\n",
    "            table_data = row.find_all('td')\n",
    "            for i in range(len(table_data)):\n",
    "                #such a hack lol, regex or something should be used, but I wanted to space out the first and last name but\n",
    "                #not affect 10,000 meters\n",
    "                perf[info_keys[i]] = self.remove_whitespace(table_data[i].text).replace(',', ', ').replace(', 0', ',0')\n",
    "            performances.append(perf)\n",
    "        return performances\n",
    "    \n",
    "    def get_athlete_bests(self, name, state, team_name, gender, season):\n",
    "        \"\"\"\n",
    "        This will scrape through the html of the athlete and return their personal bests for any event they do.\n",
    "        Will call get_athlete_html method to retrieve the html.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        name : str\n",
    "            The name of the athlete (Last_First)\n",
    "\n",
    "        state : str\n",
    "            state where the school is located. (There can be multiple universities with the same name)\n",
    "        \n",
    "        team_name : str\n",
    "            the name of the school\n",
    "        \n",
    "        gender : str\n",
    "            specifies whether we are trying to retrieve men or women's team\n",
    "\n",
    "        season : str\n",
    "            the season for the roster (*year*_Cross_Country, *year*_Indoor, or *year*_Outdoor)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary of the athlete's best marks\n",
    "        \"\"\"\n",
    "        athlete_html = self.get_athlete_html(name, state, team_name, gender, season)\n",
    "        table_bests = athlete_html.find(\"table\", class_=\"table bests\")\n",
    "        rows = table_bests.find_all(\"td\")\n",
    "        bests = {}\n",
    "        for i in range(0,len(rows), 2):\n",
    "            event = self.remove_whitespace(rows[i].text)\n",
    "            mark = self.remove_whitespace(rows[i+1].text).strip('\\\\\"').replace('m', 'm ') #hackish way of spacing metric and standard\n",
    "            if event != \"\" or mark != \"\":\n",
    "                bests[event] = mark\n",
    "        return bests\n",
    "\n",
    "    def get_athlete_results(self, name, state, team_name, gender, season):\n",
    "        \"\"\"\n",
    "        This will scrape through the html of the athlete and return history of performances.\n",
    "        This will return the information on when and where the performance was and the mark and placement for the athlete.\n",
    "        Will call get_athlete_html method to retrieve the html.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        name : str\n",
    "            The name of the athlete (Last_First)\n",
    "            \n",
    "        state : str\n",
    "            state where the school is located. (There can be multiple universities with the same name)\n",
    "        \n",
    "        team_name : str\n",
    "            the name of the school\n",
    "        \n",
    "        gender : str\n",
    "            specifies whether we are trying to retrieve men or women's team\n",
    "\n",
    "        season : str\n",
    "            the season for the roster (*year*_Cross_Country, *year*_Indoor, or *year*_Outdoor)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            list of dictionaries containing meet dates, names, and lists of performance results\n",
    "        \"\"\"\n",
    "\n",
    "        info_keys = ['event', 'result', 'place', 'final']\n",
    "        meet_results  = []\n",
    "        athlete_html = self.get_athlete_html(name, state, team_name, gender, season)\n",
    "        meet_results_table = athlete_html.find(id=\"meet-results\").find_all(\"div\")\n",
    "        for meet in meet_results_table:\n",
    "            # there are some divs in athlete results to specify whether they transferred or not, resulting in a None.\n",
    "            if meet.find(\"thead\") is not None:\n",
    "                title = meet.find(\"thead\").text.strip().replace('\\xa0\\xa0\\xa0', '')\n",
    "                meet_name, date = title.split('\\n')\n",
    "                meet_info = {}\n",
    "                meet_info['meet_name'] = meet_name\n",
    "                meet_info['date'] = date\n",
    "                table_row = meet.find_all(\"tr\")\n",
    "                meet_info['performances'] = []\n",
    "                for perf in table_row:\n",
    "                    perf_info = {}\n",
    "                    table_data = perf.find_all(\"td\")\n",
    "                    if table_data != []:\n",
    "                        table_data = [data.text.strip() for data in table_data]\n",
    "                        for i in range(len(table_data)):\n",
    "                            perf_info[info_keys[i]] = table_data[i].replace('\\xa0\\n', '').replace('\\n',' ').strip('\\\\\"')\n",
    "                        meet_info['performances'].append(perf_info)\n",
    "                meet_results.append(meet_info)\n",
    "        return meet_results\n",
    "\n",
    "    def get_soup(self, url): # gets html with beautiful soup\n",
    "        \"\"\"\n",
    "        This will use the requests library to retrieve the html from a url.\n",
    "        The BeautifulSoup library will parse the html to be processed.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        url : str\n",
    "            the url to a webpage\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        soup obj\n",
    "            the soup obj of the webpage html\n",
    "        \"\"\"\n",
    "        page = requests.get(url)\n",
    "        return BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    def get_athlete_html(self, name, state, team_name, gender, season):\n",
    "        \"\"\"\n",
    "        This will retrieve the html for a particular athlete on the Tfrrs website.\n",
    "        An athlete needs to be looked up by their team first, so their team html is first retrieved.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        name : str\n",
    "            The name of the athlete (Last_First)\n",
    "            \n",
    "        state : str\n",
    "            state where the school is located. (There can be multiple universities with the same name)\n",
    "        \n",
    "        team_name : str\n",
    "            the name of the school\n",
    "        \n",
    "        gender : str\n",
    "            specifies whether we are trying to retrieve men or women's team\n",
    "\n",
    "        season : str\n",
    "            the season for the roster (*year*_Cross_Country, *year*_Indoor, or *year*_Outdoor)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        soup obj\n",
    "            the soup obj of the webpage html\n",
    "        \"\"\"\n",
    "        team_html = self.get_team_html(state, team_name, gender, season)\n",
    "        roster_rows = self.get_table_by_heading(team_html, 'NAME')\n",
    "        for athlete_info in roster_rows: # does a look up of the athlete by name\n",
    "            if name == athlete_info.find_all('td')[0].text.strip().replace(', ','_'):\n",
    "                athlete_url = self.URL + athlete_info.find_all('a')[0]['href']\n",
    "                break\n",
    "        return self.get_soup(athlete_url) # TODO: raise exception if html not found, athlete dne or is not on the roster this season\n",
    "\n",
    "    def get_year_keys(self, state, team_name, gender): # for getting the key \"configure_hnd\" so we can get the html page from a certain year\n",
    "        \"\"\"\n",
    "        This method is essential for finding the team on a given year. Tffrs has values for each team and their corresponding\n",
    "        season. ie (2022_Cross_Country : 330)\n",
    "        This method first gets the most recent html page for a team and then finds a previous season and its value then\n",
    "        will return dictionary of the seasons and their values.\n",
    "        Parameters\n",
    "        ----------\n",
    "        state : str\n",
    "            state where the school is located. (There can be multiple universities with the same name)\n",
    "        \n",
    "        team_name : str\n",
    "            the name of the school\n",
    "        \n",
    "        gender : str\n",
    "            specifies whether we are trying to retrieve men or women's team\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            Season and its values\n",
    "        \"\"\"\n",
    "        soup = self.get_soup(self.URL + f'teams/{state.upper()}_college_{gender.lower()}_{team_name}.html')\n",
    "        form_control = soup.find(\"select\", class_=\"form-control\")\n",
    "        year_info = form_control.find_all(\"option\")\n",
    "        year_info.pop(0) # dictionary comprehension to get the keys and values for the years\n",
    "        return {year.text.strip().replace('NCAA','').replace(' ','_').replace('__','_') : str(year).split('\"')[1] for year in year_info}\n",
    "        \n",
    "    def get_team_html(self, state, team_name, gender, season):\n",
    "        \"\"\"\n",
    "        This will retrieve the html for a particular season for a team on the Tfrrs website.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        state : str\n",
    "            state where the school is located. (There can be multiple universities with the same name)\n",
    "        \n",
    "        team_name : str\n",
    "            the name of the school\n",
    "        \n",
    "        gender : str\n",
    "            specifies whether we are trying to retrieve men or women's team\n",
    "\n",
    "        season : str\n",
    "            the season for the roster (*year*_Cross_Country, *year*_Indoor, or *year*_Outdoor)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        soup obj\n",
    "            the soup obj of the webpage html\n",
    "        \"\"\"\n",
    "        page_url = self.URL + f'teams/{state.upper()}_college_{gender.lower()}_{team_name}.html'\n",
    "        year_keys = self.get_year_keys(state, team_name, gender) # retrieve the value for the season we want to find\n",
    "        page_url += f'?config_hnd={year_keys[season]}'\n",
    "        return self.get_soup(page_url)\n",
    "\n",
    "    def get_table_by_heading(self, html, heading):# TODO: update docs\n",
    "        \"\"\" \n",
    "        Returns the table rows for a table given team page html and a heading.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        html : soup obj\n",
    "            The html of a specified team page\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            list of table rows\n",
    "        \"\"\"\n",
    "        html_tables = html.find_all(\"table\", class_=\"tablesaw\")\n",
    "        for table in html_tables: # there are multiple tables on some pages especially with track teams\n",
    "            if table.find('th').text.strip() == heading: # we are identifying the table by a header definitely a hack\n",
    "                found_table = table\n",
    "                break\n",
    "        roster_rows = found_table.find_all(\"tr\")\n",
    "        roster_rows.pop(0) # pop the first item in the list because it is just NAME and YEAR\n",
    "        return roster_rows\n",
    "\n",
    "    def remove_whitespace(self, string):\n",
    "        \"\"\"\n",
    "        removes whitespace characters like \\n and \\t \n",
    "\n",
    "        Paramters\n",
    "        ---------\n",
    "        string : str\n",
    "            string we want to remove white space from\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            string stripped of whitespace\n",
    "        \"\"\"\n",
    "        pattern = re.compile(r'\\s+')\n",
    "        return re.sub(pattern, '', string)\n",
    "h = Hermes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h.get_athlete_results('Mastro_Shane', 'PA', 'Moravian', 'm', '2022_Outdoor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Burrier, Lance', 'year': 'SO-2'},\n",
       " {'name': 'Calantoni, Marco', 'year': 'SO-2'},\n",
       " {'name': 'Cherubin, Ethan', 'year': 'JR-3'},\n",
       " {'name': 'Clemson, Brad', 'year': 'SR-4'},\n",
       " {'name': 'DeRafelo, Dominic', 'year': 'SR-4'},\n",
       " {'name': 'Duffy, Liam', 'year': 'JR-3'},\n",
       " {'name': 'Farrell, Jake', 'year': 'FR-1'},\n",
       " {'name': 'Ford, Jordan', 'year': 'SO-2'},\n",
       " {'name': 'Frank, Casey', 'year': 'SO-2'},\n",
       " {'name': 'Gartner, Jason', 'year': 'FR-1'},\n",
       " {'name': 'Gildea, Adam', 'year': 'SO-2'},\n",
       " {'name': 'Gingrich, Peter', 'year': 'SR-4'},\n",
       " {'name': 'Glennon, Richard', 'year': 'SR-4'},\n",
       " {'name': 'Goll, Jeremy', 'year': 'SO-2'},\n",
       " {'name': 'Gray, Trevor', 'year': 'FR-1'},\n",
       " {'name': 'Hajel, Nathan', 'year': 'FR-1'},\n",
       " {'name': 'Houghton, Shane', 'year': 'SR-4'},\n",
       " {'name': 'Jancsarics, Christian', 'year': 'JR-3'},\n",
       " {'name': 'Jenkins, Dan', 'year': 'SO-2'},\n",
       " {'name': 'Keck, Eric', 'year': 'JR-3'},\n",
       " {'name': 'King, Tim', 'year': 'SR-4'},\n",
       " {'name': 'Kleinberg, Geoffrey', 'year': 'FR-1'},\n",
       " {'name': 'Lerch, Michael', 'year': 'SR-4'},\n",
       " {'name': 'Mangini, Josh', 'year': 'SO-2'},\n",
       " {'name': 'Mason, Derek', 'year': 'SO-2'},\n",
       " {'name': 'Mastro, Shane', 'year': 'SR-4'},\n",
       " {'name': 'McNicholas, Dan', 'year': 'SO-2'},\n",
       " {'name': 'Nahf, Owen', 'year': 'FR-1'},\n",
       " {'name': 'Nomura, Niko', 'year': 'FR-1'},\n",
       " {'name': 'Pavone, Matt', 'year': 'FR-1'},\n",
       " {'name': 'Petre, Paul', 'year': 'SO-2'},\n",
       " {'name': 'Poniktera, Wyatt', 'year': 'FR-1'},\n",
       " {'name': 'Sabastro, Owen', 'year': 'FR-1'},\n",
       " {'name': 'Santos, Jared', 'year': 'SO-2'},\n",
       " {'name': 'Schuman, Max', 'year': 'SR-4'},\n",
       " {'name': 'Shea, Matt', 'year': 'SO-2'},\n",
       " {'name': 'Tivade, Joe', 'year': 'FR-1'},\n",
       " {'name': 'Ward, Brendon', 'year': 'SO-2'}]"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.get_roster('PA', 'Moravian', 'm', '2022_Outdoor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'800': '1:54.21',\n",
       " '5000': '13:11.30',\n",
       " '1500': '3:37.75',\n",
       " '10K(XC)': '28:57.5',\n",
       " 'MILE': '3:56.00',\n",
       " '8K(XC)': '22:30.8',\n",
       " '3000': '7:59.02'}"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "athlete = {'Name': 'Young_Nico', 'State': 'AZ', 'Team-name': 'Northern_Arizona', 'Gender': 'm', 'Season': '2021_Cross_Country'}\n",
    "ath = ('Young_Nico', 'AZ', 'Northern_Arizona', 'm', '2021_Cross_Country')\n",
    "h.get_athlete_bests(*ath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_performances(state, team_name, gender, season):\n",
    "    info_keys = ['event', 'result', 'place', 'final']\n",
    "    team_html = h.get_team_html(state, team_name, gender, season)\n",
    "    rows = h.get_table_by_heading(team_html, 'EVENT')\n",
    "    performances = []\n",
    "    for row in rows:\n",
    "        perf = {}\n",
    "        table_data = row.find_all('td')\n",
    "        for i in range(len(table_data)):\n",
    "            perf[info_keys[i]] = h.remove_whitespace(table_data[i].text).replace(',', ', ')\n",
    "        performances.append(perf)\n",
    "    return performances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'event': '100',\n",
       "  'result': 'Williams, Micah',\n",
       "  'place': 'SO-2',\n",
       "  'final': '9.83'},\n",
       " {'event': '200',\n",
       "  'result': 'Williams, Micah',\n",
       "  'place': 'SO-2',\n",
       "  'final': '20.05'},\n",
       " {'event': '400',\n",
       "  'result': 'Mafilas, Evan',\n",
       "  'place': 'SR-4',\n",
       "  'final': '47.03'},\n",
       " {'event': '800',\n",
       "  'result': 'Peralta, Luis',\n",
       "  'place': 'SO-2',\n",
       "  'final': '1:47.92'},\n",
       " {'event': '1500',\n",
       "  'result': 'Brown, Reed',\n",
       "  'place': 'SR-4',\n",
       "  'final': '3:36.44'},\n",
       " {'event': '3000',\n",
       "  'result': 'Holland, EJ',\n",
       "  'place': 'FR-1',\n",
       "  'final': '8:33.95'},\n",
       " {'event': '5000',\n",
       "  'result': 'Bienenfeld, Aaron',\n",
       "  'place': 'SR-4',\n",
       "  'final': '13:28.13'},\n",
       " {'event': '10, 000',\n",
       "  'result': 'Bienenfeld, Aaron',\n",
       "  'place': 'SR-4',\n",
       "  'final': '28:14.67'},\n",
       " {'event': '110H', 'result': 'Mundy, Will', 'place': 'JR-3', 'final': '14.19'},\n",
       " {'event': '400H', 'result': 'Mundy, Will', 'place': 'JR-3', 'final': '50.71'},\n",
       " {'event': '3000S',\n",
       "  'result': 'Norman, Quincy',\n",
       "  'place': 'SO-2',\n",
       "  'final': '8:58.81'},\n",
       " {'event': '4x100',\n",
       "  'result': 'RyanMulholland, MicahWilliams, WillMundy, XavierNairne',\n",
       "  'place': '',\n",
       "  'final': '38.83'},\n",
       " {'event': '4x400',\n",
       "  'result': 'NathanPoff, EvanMafilas, MatthewErickson, WillMundy',\n",
       "  'place': '',\n",
       "  'final': '3:09.61'},\n",
       " {'event': '4xMile',\n",
       "  'result': 'ReedBrown, JackYearian, ElliottCook, EJHolland',\n",
       "  'place': '',\n",
       "  'final': '16:29.87'},\n",
       " {'event': 'HJ', 'result': 'Kinder, Jett', 'place': 'SO-2', 'final': '2.00m'},\n",
       " {'event': 'PV',\n",
       "  'result': 'Canfield, Harrison',\n",
       "  'place': 'FR-1',\n",
       "  'final': '4.95m'},\n",
       " {'event': 'LJ',\n",
       "  'result': 'LaCoste, Pierce',\n",
       "  'place': 'JR-3',\n",
       "  'final': '7.73m'},\n",
       " {'event': 'TJ',\n",
       "  'result': 'Ihemeje, Emmanuel',\n",
       "  'place': 'SO-2',\n",
       "  'final': '17.03m'},\n",
       " {'event': 'SP', 'result': 'Vollmer, Max', 'place': 'JR-3', 'final': '15.12m'},\n",
       " {'event': 'DT',\n",
       "  'result': 'Brewster, Travis',\n",
       "  'place': 'JR-3',\n",
       "  'final': '49.65m'},\n",
       " {'event': 'HT',\n",
       "  'result': 'Strunk, Mason',\n",
       "  'place': 'FR-1',\n",
       "  'final': '65.43m'},\n",
       " {'event': 'JT', 'result': 'Hampton, Ty', 'place': 'FR-1', 'final': '77.08m'},\n",
       " {'event': 'Dec', 'result': 'Vollmer, Max', 'place': 'JR-3', 'final': '8022'}]"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "get_top_performances('OR', 'Oregon', 'm', '2022_Outdoor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1500': '4:02.45',\n",
       " '3000S': '9:28.51',\n",
       " 'MILE': '4:23.99',\n",
       " '5K(XC)': '18:50.0',\n",
       " '3000': '8:38.08',\n",
       " '6K(XC)': '18:55.1',\n",
       " '5000': '15:09.74',\n",
       " '8K(XC)': '25:33.0'}"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.get_athlete_bests('Houghton_Shane', 'PA', 'Moravian', 'm', '2022_Outdoor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.tfrrs.org/teams/tf/PA_college_m_Moravian.html?config_hnd=255\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('readme.txt', 'w') as f:\n",
    "    f.write(str(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.tfrrs.org/teams/tf/PA_college_m_Moravian.html?config_hnd=255\") # for moravian\n",
    "with open('test_team_page.html', 'wb+') as f:\n",
    "    f.write(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "page = requests.get(\"https://www.tfrrs.org/athletes/6873033/Moravian/Shane__Houghton\") # for distance runner\n",
    "with open('test_distance_runner.html', 'wb+') as f:\n",
    "    f.write(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.tfrrs.org/athletes/6537261/Moravian/Shane_Mastro\") # for thrower\n",
    "with open('test_thrower.html', 'wb+') as f:\n",
    "    f.write(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.tfrrs.org/athletes/7983217/Moravian/Trevor_Gray\") # for sprinter\n",
    "with open('test_sprinter.html', 'wb+') as f:\n",
    "    f.write(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://www.tfrrs.org/athletes/7983219/Moravian/Owen_Sabastro\") # for sprint/jumper\n",
    "with open('test_sprint_jumper.html', 'wb+') as f:\n",
    "    f.write(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saving.html', 'rb') as f:\n",
    "    soup = BeautifulSoup(f.read(), 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "page = requests.get(\"https://www.tfrrs.org/teams/PA_college_m_Moravian.html\") # for basic team page\n",
    "with open('basic_team_page.html', 'wb+') as f:\n",
    "    f.write(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2022_Outdoor': '255',\n",
       " '2021-22_Indoor': '240',\n",
       " '2021_Cross_Country': '224',\n",
       " '2021_Outdoor': '216',\n",
       " '2020-21_Indoor': '205',\n",
       " '2020_Cross_Country': '197',\n",
       " '2020_Outdoor': '189',\n",
       " '2019-20_Indoor': '178',\n",
       " '2019_Cross_Country': '169',\n",
       " '2019_Outdoor': '160',\n",
       " '2018-19_Indoor': '148',\n",
       " '2018_Cross_Country': '140',\n",
       " '2018_Outdoor': '131',\n",
       " '2017-2018_Indoor': '125',\n",
       " '2017_Cross_Country': '117',\n",
       " '2017_Outdoor': '110',\n",
       " '2016-2017_Indoor': '104',\n",
       " '2016_Cross_Country': '98',\n",
       " '2016_Outdoor': '93',\n",
       " '2015-2016_Indoor': '85',\n",
       " '2015_Cross_Country': '80',\n",
       " '2015_Outdoor': '74',\n",
       " '2014-2015_Indoor': '67',\n",
       " '2014_Cross_Country': '63',\n",
       " '2014_Outdoor': '56',\n",
       " '2013-2014_Indoor': '49',\n",
       " '2013_Cross_Country': '45',\n",
       " '2013_Outdoor': '42',\n",
       " '2012-2013_Indoor': '31',\n",
       " '2012_Cross_Country': '27',\n",
       " '2012_Outdoor': '23',\n",
       " '2011-12_Indoor': '19',\n",
       " '2011_Outdoor': '15',\n",
       " '2010-11_Indoor': '11',\n",
       " '2010_Outdoor': '7',\n",
       " '2009-10_Indoor': '3'}"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.get_year_keys('PA', 'Moravian', 'm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hermes import Hermes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Burrier, Lance', 'year': 'SO-2'},\n",
       " {'name': 'Calantoni, Marco', 'year': 'SO-2'},\n",
       " {'name': 'Cherubin, Ethan', 'year': 'JR-3'},\n",
       " {'name': 'Clemson, Brad', 'year': 'SR-4'},\n",
       " {'name': 'DeRafelo, Dominic', 'year': 'SR-4'},\n",
       " {'name': 'Duffy, Liam', 'year': 'JR-3'},\n",
       " {'name': 'Farrell, Jake', 'year': 'FR-1'},\n",
       " {'name': 'Ford, Jordan', 'year': 'SO-2'},\n",
       " {'name': 'Frank, Casey', 'year': 'SO-2'},\n",
       " {'name': 'Gartner, Jason', 'year': 'FR-1'},\n",
       " {'name': 'Gildea, Adam', 'year': 'SO-2'},\n",
       " {'name': 'Gingrich, Peter', 'year': 'SR-4'},\n",
       " {'name': 'Glennon, Richard', 'year': 'SR-4'},\n",
       " {'name': 'Goll, Jeremy', 'year': 'SO-2'},\n",
       " {'name': 'Gray, Trevor', 'year': 'FR-1'},\n",
       " {'name': 'Hajel, Nathan', 'year': 'FR-1'},\n",
       " {'name': 'Houghton, Shane', 'year': 'SR-4'},\n",
       " {'name': 'Jancsarics, Christian', 'year': 'JR-3'},\n",
       " {'name': 'Jenkins, Dan', 'year': 'SO-2'},\n",
       " {'name': 'Keck, Eric', 'year': 'JR-3'},\n",
       " {'name': 'King, Tim', 'year': 'SR-4'},\n",
       " {'name': 'Kleinberg, Geoffrey', 'year': 'FR-1'},\n",
       " {'name': 'Lerch, Michael', 'year': 'SR-4'},\n",
       " {'name': 'Mangini, Josh', 'year': 'SO-2'},\n",
       " {'name': 'Mason, Derek', 'year': 'SO-2'},\n",
       " {'name': 'Mastro, Shane', 'year': 'SR-4'},\n",
       " {'name': 'McNicholas, Dan', 'year': 'SO-2'},\n",
       " {'name': 'Nahf, Owen', 'year': 'FR-1'},\n",
       " {'name': 'Nomura, Niko', 'year': 'FR-1'},\n",
       " {'name': 'Pavone, Matt', 'year': 'FR-1'},\n",
       " {'name': 'Petre, Paul', 'year': 'SO-2'},\n",
       " {'name': 'Poniktera, Wyatt', 'year': 'FR-1'},\n",
       " {'name': 'Sabastro, Owen', 'year': 'FR-1'},\n",
       " {'name': 'Santos, Jared', 'year': 'SO-2'},\n",
       " {'name': 'Schuman, Max', 'year': 'SR-4'},\n",
       " {'name': 'Shea, Matt', 'year': 'SO-2'},\n",
       " {'name': 'Tivade, Joe', 'year': 'FR-1'},\n",
       " {'name': 'Ward, Brendon', 'year': 'SO-2'}]"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = Hermes()\n",
    "h.get_roster('PA', 'Moravian', 'm', '2022_Outdoor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72178ffac913d3c015f5f5a3069c4fdd5bf5a8d1614067a7ed7ac038311f7fdd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
